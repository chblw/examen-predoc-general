\chapter{Chaînes de Markov}

\begin{enumerate}
	\item Soit $\{X_n, n = 0, 1, \dots\}$, un processus qui peut prendre un nombre fini ou comptable d'états. 
	\item Si le processus est dans l'état $i$ au temps $n$, on le note $X_n = i$. 
	\item Si le processus est dans l'état $i$, il a une probabilité fixe, notée $P_{ij}$, que le processus sera dans l'état $j$ au prochain état. 
	\item Ce processus est appelé un processus de Markov. 
\end{enumerate}

On a $$P_{ij} \geq 0, i, j \geq 0$$
et
$$\sum_{j =0 }^{\infty} P_{ij} = 1, i = 0, 1, \dots .$$
Les probabilités sont présentés dans une matrice de transition
$$P = \left|\begin{array}{ccccc}
	P_{00} & P_{01} & \dots & P_{0j} & \dots \\
	P_{10} & P_{11} & \dots & P_{1j} & \dots \\
	\vdots & \vdots & \ddots & \vdots & \dots \\
	P_{i0} & P_{i1} & \dots & P_{ij} & \dots \\
	\vdots & \vdots & \vdots & \vdots & \ddots 
\end{array}\right|$$

\section{Équations Chapman-Kolmogorov}

On étudie les probabilité de transition pour plus d'une période. Soit 
$$P_{ij}^{n} = \Pr(X_{n+k} = j \vert X_k = i), \quad n\geq 0, i, j \geq 0.$$
Pour calculer ces valeurs, on a 
$$P_{ij}^{n+1} = \sum_{k = 0}^{\infty} P_{ik}^nP_{kj}^m \quad \text{ pour }n, m \geq 0 ~\forall~ i, j.$$
Intuition : la probabilité de partir de $i$ et finir à $j$ est la somme de tous les chemins possibles. En notation matricielle, on a 
$$P^{n+m} = P^n P^m.$$

\subsection{Probabilités de visiter un état}

On s'intéresse à la probabilité qu'un processus visite un état à un moment. Pour ce faire, on créer un état absorbant.  

\begin{align*}
Q_{i,j} &= P_{i,j}, \text{ si } \notin \mathcal{A}, j\notin \mathcal{A}\\
Q_{i,A} &= \sum_{j\in \mathcal{A}} P_{i,j}, \text{ si } i\notin \mathcal{A}\\
Q_{A, A} &= 1.
\end{align*}

\section{Classification des états}

\begin{itemize}
	\item L'état $j$ est dit accessible de l'état $i$ si $P_{ij}^n > 0$ pour un $n\geq 0$
	\item Deux états $i$ et $j$ qui sont accessibles l'un à l'autre sont appelés des états communicants et on les note $i\leftrightarrow j$
	\item Deux états qui communiques sont appelés dans la même classe
	\item Une chaîne de Markov avec une seule classe est appelée irréductible
	\item Pour un état $i$, on note $f_i$ la probabilité que partant de l'état $i$, le processus revisitera l'état $i$. 
	\begin{itemize}
		\item Si $f_i = 1$, on note l'état $i$ récurrent. On a aussi 
		$$\sum_{n = 1}^{\infty} P_{ii}^n = \infty$$
		\item Si $f_i < 1$, on note l'état transient. La probabilité que le processus sera dans l'état $i$ pour $n$ périodes est une distribution géométrique. On a aussi
		$$\sum_{n = 1}^{\infty} P_{ii}^n < \infty$$
	\end{itemize}
	\item Si $i$ est réccurent, et $i$ communique avec $j$, alors $j$ est aussi récurrent. 
\end{itemize}

\section{Probabilités limites}

\begin{theoreme}{}{}
	Pour une chaîne de Markov irréductible et ergodique, $\lim\limits_{n\to \infty}P_{ij}^n$ existe et est indépendant de $i$. De plus, avec 
	$$\pi_j = \lim\limits_{n\to\infty}P_{ij}^n, \quad j\geq 0$$
	alors $\pi_j$ est la solution positive unique de 
	\begin{align*}
	\pi_j &= \sum_{i = 0}^{\infty} \pi_iP_{ij}, \quad j\geq 0,\\
	\sum_{j = 0}^{\infty}\pi_j &= 1. 
	\end{align*}
\end{theoreme}




















